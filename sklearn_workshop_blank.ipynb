{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# suppress warnings (quite prevalent with pandas and numpy)\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "pd.options.display.max_rows = 1000\n",
    "\n",
    "# maintain directories well defined\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "ALL_DATA_DIR = \"dat\"\n",
    "DATA_DIR = \"novel-covid-data\"\n",
    "DATA_PATH = os.path.join(PROJECT_ROOT_DIR, ALL_DATA_DIR, DATA_DIR)\n",
    "\n",
    "# global variables - desired columns from dataset\n",
    "COLS = [\"SNo\", \"ObservationDate\", \"Province/State\", \"Country/Region\", \"Confirmed\", \"Deaths\"]\n",
    "\n",
    "# function for initialization\n",
    "def initialize_data(dataset, data_path=DATA_PATH, cols=COLS):\n",
    "\n",
    "# link to data - https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset#covid_19_data.csv\n",
    "# initialize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = data[data[\"Province/State\"]==\"Recovered\"].index\n",
    "data.drop(indexes, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# unstratified split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratified split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check sampling ratios for US as comparison\n",
    "# stratified\n",
    "print(\"Stratified Test: \", strat_test_set[\"Country/Region\"].value_counts()[\"US\"]/len(strat_test_set))\n",
    "print(\"Stratified Train: \", strat_train_set[\"Country/Region\"].value_counts()[\"US\"]/len(strat_train_set))\n",
    "\n",
    "# unstratified\n",
    "print(\"UnStratified Test: \", test_set[\"Country/Region\"].value_counts()[\"US\"]/len(test_set))\n",
    "print(\"UnStratified Train: \", train_set[\"Country/Region\"].value_counts()[\"US\"]/len(train_set))\n",
    "\n",
    "# original data\n",
    "print(\"Original Data: \", data[\"Country/Region\"].value_counts()[\"US\"]/len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_data = strat_train_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_groups = covid_data.groupby(\"Country/Region\")\n",
    "missing_all = []\n",
    "missing_none = []\n",
    "missing_some = []\n",
    "for k, df in country_groups: \n",
    "    if df[\"Province/State\"].isnull().all():\n",
    "        missing_all.append(k)\n",
    "    elif df[\"Province/State\"].isnull().any():\n",
    "        if (~df[\"Province/State\"].isnull()).all():\n",
    "            missing_none.append(k)\n",
    "        else: \n",
    "            missing_some.append(k)\n",
    "\n",
    "# print(missing_all, missing_none, missing_some)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_to_province(df, col_name=\"Region\"):\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_data[\"ObsDate\"] = pd.to_datetime(covid_data[\"ObservationDate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def days_since_first_obs(df, col_name=\"Day_Delta\"):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "# define a list of numerical attributes and categorical attributes\n",
    "num_attributes = [\"Confirmed\", \"Day_Delta\", \"Deaths\", \"SNo\"]\n",
    "cat_attributes = [\"ObservationDate\", \"Region\"]\n",
    "\n",
    "scatter_matrix(covid_data[num_attributes], figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# imputer -> fillnas based on a policy and save statistics for later use (numerical features)\n",
    "\n",
    "\n",
    "# imputer is only for numerical features so lets try it out\n",
    "\n",
    "\n",
    "# in this case, the .fit method is simply calculating the medians of each feature\n",
    "\n",
    "\n",
    "# imputer also saves statistics (median) as this will be of use if we need to transform new incoming data\n",
    "# we won't have to re-fit the imputer instance\n",
    "# some of our features may not even have had missing values, but the imputer applied the computation anyways\n",
    "# print(imputer.statistics_)\n",
    "\n",
    "# the transform method (which actually fills nas) returns a numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# the onehotencoder turns categorical variables in to binary values for each possible value of a feature \n",
    "# this avoids \"confusion\" on the model's part, regarding distance related relationships \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# standard scaler -> scale numerical features with scaling/standardization/normalization methods\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
