{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import math\n",
    "\n",
    "# suppress warnings (quite prevalent with pandas and numpy)\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "pd.options.display.max_rows = 1000\n",
    "\n",
    "# maintain directories well defined\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "ALL_DATA_DIR = \"dat\"\n",
    "DATA_DIR = \"novel-covid-data\"\n",
    "DATA_PATH = os.path.join(PROJECT_ROOT_DIR, ALL_DATA_DIR, DATA_DIR)\n",
    "\n",
    "# global variables - desired columns from dataset\n",
    "COLS = [\"SNo\", \"ObservationDate\", \"Province/State\", \"Country/Region\", \"Confirmed\", \"Deaths\"]\n",
    "\n",
    "# function for initialization\n",
    "def initialize_data(dataset, data_path=DATA_PATH, cols=COLS):\n",
    "    csv_path = os.path.join(data_path, dataset)\n",
    "    data = pd.read_csv(csv_path, usecols=cols)\n",
    "    return data\n",
    "\n",
    "# link to data - https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset#covid_19_data.csv\n",
    "# initialize\n",
    "data = initialize_data(\"covid_19_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miscellaneous drops that need to be applied to the entire data \n",
    "indexes = data[data[\"Province/State\"]==\"Recovered\"].index\n",
    "data.drop(indexes, inplace = True)\n",
    "data.dropna(subset=[\"Deaths\"], inplace = True)\n",
    "\n",
    "country_counts = data[\"Country/Region\"].value_counts()\n",
    "labels = data[\"Country/Region\"].astype('category').cat.categories.tolist()\n",
    "singles = [i for i in labels if country_counts[i] == 1]\n",
    "for i in singles:\n",
    "    indexes = data[data[\"Country/Region\"] == i].index\n",
    "    data.drop(indexes, inplace = True)\n",
    "    \n",
    "covid_data = data\n",
    "\n",
    "\n",
    "# feature adding functions    \n",
    "def country_to_province(df, col_name=\"Region\"):\n",
    "    df.loc[df[\"Province/State\"].isnull(), col_name] = df[\"Country/Region\"] \n",
    "    df.loc[(~df[\"Province/State\"].isnull()), col_name] = df[\"Province/State\"] \n",
    "\n",
    "def days_since_first_obs(df, col_name=\"Day_Delta\"):\n",
    "    df[\"ObsDate\"]= pd.to_datetime(df[\"ObservationDate\"])\n",
    "    region_groups = df.groupby(\"Region\")\n",
    "    df[col_name] = np.nan\n",
    "    for k, group in region_groups:\n",
    "        group.sort_values(by=\"ObsDate\", inplace = True)\n",
    "        first_day = group.iloc[0][\"ObsDate\"]\n",
    "        for i in range(len(group)):\n",
    "            df.ix[(group.iloc[i][\"SNo\"]-1), col_name] = (group.iloc[i][\"ObsDate\"] - first_day).days\n",
    "    df.drop(\"ObsDate\", axis = 1, inplace = True)\n",
    "\n",
    "country_to_province(covid_data)\n",
    "days_since_first_obs(covid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_attrbs = [\"ObservationDate\", \"Province/State\", \"Country/Region\", \"Region\"]\n",
    "num_attrbs = [\"SNo\", \"Confirmed\", \"Deaths\", \"Day_Delta\"]\n",
    "covid_data_num = covid_data.copy()\n",
    "covid_data_cat = covid_data.copy()\n",
    "covid_data_num.drop(columns = cat_attrbs, inplace=True)\n",
    "covid_data_cat.drop(columns = num_attrbs, inplace=True)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "imputer = SimpleImputer(strategy = \"most_frequent\")\n",
    "covid_data_cat = imputer.fit_transform(covid_data_cat)\n",
    "one_hot = OneHotEncoder()\n",
    "covid_data_cat = one_hot.fit_transform(covid_data_cat).toarray()\n",
    "num_imputer = SimpleImputer(strategy = \"median\")\n",
    "covid_data_num = imputer.fit_transform(covid_data_num)\n",
    "\n",
    "covid_data = np.concatenate((covid_data_num, covid_data_cat), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNo_ix, confirmed_ix, deaths_ix, day_delta_ix = 0,1,2,3\n",
    "\n",
    "covid_datadf = pd.DataFrame(covid_data)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# unstratified split\n",
    "train_set, test_set = train_test_split(covid_datadf, test_size=0.2, random_state=42)\n",
    "train_labels = train_set[deaths_ix].copy()\n",
    "test_labels = test_set[deaths_ix].copy()\n",
    "train_set.drop(deaths_ix, axis = 1, inplace = True)\n",
    "test_set.drop(deaths_ix, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(train_set, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "lr_covid_predict = lin_reg.predict(train_set)\n",
    "lin_score = r2_score(train_labels, lr_covid_predict)\n",
    "lin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_data = train_set.iloc[8000:8050]\n",
    "some_labels = train_labels.iloc[8000:8050]\n",
    "\n",
    "some_predictions = (lin_reg.predict(some_data))\n",
    "some_labels = list(np.array(some_labels))\n",
    "for i in range(len(some_labels)):\n",
    "    print(\"predicted: {}, actual : {}\\n\".format(some_predictions[i], some_labels[i]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(train_set, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_covid_predict = tree_reg.predict(train_set)\n",
    "tree_score = r2_score(train_labels, tree_covid_predict)\n",
    "tree_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(train_set, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_covid_predict = forest_reg.predict(train_set)\n",
    "forest_score = r2_score(train_labels, forest_covid_predict)\n",
    "forest_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_data = train_set.iloc[9000:10050]\n",
    "some_labels = train_labels.iloc[9000:10050]\n",
    "\n",
    "some_predictions = (forest_reg.predict(some_data))\n",
    "some_labels = list(np.array(some_labels))\n",
    "for i in range(len(some_labels)):\n",
    "    print(\"predicted: {}, actual : {}\\n\".format(some_predictions[i], some_labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# cross-validating - training n-1 folds of the training data and testing on the remaining one. repeat n times for \n",
    "# n accuracy scores. \n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores: \", scores)\n",
    "    print(\"Means: \", scores.mean())\n",
    "    print(\"STD: \", scores.std())\n",
    "\n",
    "tree_scores = cross_val_score(tree_reg, covid_data_prepared, covid_labels, cv=7)\n",
    "tree_rmse_scores = np.sqrt(tree_scores)    \n",
    "lin_scores = cross_val_score(lin_reg, covid_data_prepared, covid_labels, cv=7)\n",
    "lin_rmse_scores = np.sqrt(lin_scores)  \n",
    "forest_scores = cross_val_score(forest_reg, covid_data_prepared, covid_labels, cv=7)\n",
    "forest_rmse_scores = np.sqrt(forest_scores)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_scores(tree_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_scores(lin_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_scores(forest_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# sklearn will play with different combinations of hyperparameters to fine tune your model for you \n",
    "\n",
    "param_grid = [\n",
    "{'n_estimators': [10, 30, 100], 'max_features': [2, 8, 16]},\n",
    "{'bootstrap': [False], 'n_estimators': [30, 100], 'max_features': [8, 16]},\n",
    "]\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=7)\n",
    "grid_search.fit(covid_data_prepared, covid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator = forest_reg, param_distributions = random_grid, n_iter = 50, cv = 7, \n",
    "                                   verbose=2, random_state=42, n_jobs = -1)\n",
    "random_search.fit(train_set, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = random_search.cv_results_\n",
    "for score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "final_forest = RandomForestRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',\n",
    "                      max_depth=40, max_features='auto', max_leaf_nodes=None,\n",
    "                      max_samples=None, min_impurity_decrease=0.0,\n",
    "                      min_impurity_split=None, min_samples_leaf=1,\n",
    "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                      n_estimators=1400, n_jobs=None, oob_score=False,\n",
    "                      random_state=None, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=40, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=1400, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forest.fit(train_set, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9933627095762859"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "forest_final_predict = final_forest.predict(test_set)\n",
    "forest_score = r2_score(test_labels, forest_final_predict)\n",
    "forest_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: 78.16357142857143, actual : 97.0\n",
      "\n",
      "predicted: 2.0, actual : 2.0\n",
      "\n",
      "predicted: 0.0, actual : 0.0\n",
      "\n",
      "predicted: 251.28571428571428, actual : 256.0\n",
      "\n",
      "predicted: 22.0, actual : 22.0\n",
      "\n",
      "predicted: 0.38698630136986284, actual : 0.0\n",
      "\n",
      "predicted: 0.0, actual : 0.0\n",
      "\n",
      "predicted: 0.0, actual : 0.0\n",
      "\n",
      "predicted: 5.742857142857233, actual : 6.0\n",
      "\n",
      "predicted: 5.742857142857233, actual : 6.0\n",
      "\n",
      "predicted: 3.0, actual : 3.0\n",
      "\n",
      "predicted: 0.0, actual : 0.0\n",
      "\n",
      "predicted: 0.09154929577464443, actual : 0.0\n",
      "\n",
      "predicted: 0.0, actual : 0.0\n",
      "\n",
      "predicted: 30.192857142857143, actual : 26.0\n",
      "\n",
      "predicted: 0.25, actual : 0.0\n",
      "\n",
      "predicted: 2.4385714285714286, actual : 4.0\n",
      "\n",
      "predicted: 2055.8714285714286, actual : 2248.0\n",
      "\n",
      "predicted: 7.0, actual : 7.0\n",
      "\n",
      "predicted: 11.732142857142858, actual : 18.0\n",
      "\n",
      "predicted: 8.0, actual : 8.0\n",
      "\n",
      "predicted: 5.232142857142857, actual : 3.0\n",
      "\n",
      "predicted: 0.013157894736842386, actual : 0.0\n",
      "\n",
      "predicted: 0.015723270440251274, actual : 0.0\n",
      "\n",
      "predicted: 3575.565, actual : 3600.0\n",
      "\n",
      "predicted: 34.90785714285714, actual : 35.0\n",
      "\n",
      "predicted: 0.0, actual : 0.0\n",
      "\n",
      "predicted: 0.09154929577464443, actual : 0.0\n",
      "\n",
      "predicted: 27.359285714285715, actual : 31.0\n",
      "\n",
      "predicted: 13.0, actual : 13.0\n",
      "\n",
      "predicted: 23.757142857142856, actual : 25.0\n",
      "\n",
      "predicted: 451.6514285714286, actual : 287.0\n",
      "\n",
      "predicted: 567.7, actual : 596.0\n",
      "\n",
      "predicted: 1.0, actual : 1.0\n",
      "\n",
      "predicted: 0.015723270440251274, actual : 0.0\n",
      "\n",
      "predicted: 0.09154929577464443, actual : 0.0\n",
      "\n",
      "predicted: 0.09154929577464443, actual : 0.0\n",
      "\n",
      "predicted: 4.0, actual : 1.0\n",
      "\n",
      "predicted: 0.25, actual : 1.0\n",
      "\n",
      "predicted: 0.11827956989247661, actual : 0.0\n",
      "\n",
      "predicted: 1.0, actual : 1.0\n",
      "\n",
      "predicted: 0.0, actual : 0.0\n",
      "\n",
      "predicted: 0.0, actual : 0.0\n",
      "\n",
      "predicted: 0.0, actual : 0.0\n",
      "\n",
      "predicted: 0.25, actual : 0.0\n",
      "\n",
      "predicted: 0.11827956989247661, actual : 1.0\n",
      "\n",
      "predicted: 10.864285714285714, actual : 6.0\n",
      "\n",
      "predicted: 0.015723270440251274, actual : 0.0\n",
      "\n",
      "predicted: 0.0, actual : 0.0\n",
      "\n",
      "predicted: 0.0, actual : 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "some_data = test_set.iloc[1000:1050]\n",
    "some_labels = test_labels.iloc[1000:1050]\n",
    "\n",
    "some_predictions = (final_forest.predict(some_data))\n",
    "some_labels = list(np.array(some_labels))\n",
    "for i in range(len(some_labels)):\n",
    "    print(\"predicted: {}, actual : {}\\n\".format(some_predictions[i], some_labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
